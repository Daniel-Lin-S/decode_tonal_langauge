dataset:
  syllable_labels: ["mi", "ma"]          # Labels for syllable targets
  tone_labels: ["tone1", "tone2", "tone3", "tone4"]        # Labels for tone targets

preprocess:
  module: preprocess_main
  params:
    pipeline:
      module: preprocess.pipelines.subject_block
      params:
        subject_dirs:
          - Sub1/tdt
          - Sub2/tdt
        subject_ids: [1, 2]
    io:
      module: preprocess.io.tdt_blocks
      params:
        root_dir: data/raw
        output_dir: data/processed
    preprocessor:
      module: preprocess.preprocessor
    modalities:
      ecog:
        type: signal
        preprocessing:
          steps:
            - module: preprocess.downsample
              params:
                downsample_freq: 400

            - module: preprocess.frequency_filter
              params:
                bands:
                  - method: hilbert
                    params:
                      freq_ranges: [70, 150]
                      envelope: true
                  - method: butter
                    params:
                      freqs: [0.3, 100]
                      filter_type: bandpass

            - module: preprocess.zscore_rereference
              params:
                rereference_interval: [0., 25.]
      audio:
        type: signal

sample_collection:
  module: extract_samples
  params:
    modules:
      interval_extractor:
        module: data_loading.text_align
        function: handle_textgrids
      sample_extractor:
        module: data_loading.text_align
        function: extract_ecog_audio
    io:
      recording_dir: data/processed                                 # Root of processed recordings
      output_dir: data/samples                                    # Output path for samples
      textgrid_root: data                                         # Root directory for textgrid files
    subjects:
      1:
        interval_extractor:
          data_dir: subject_1/annotations
          start_offset: 0.2                               # Offset (in seconds) to extract before the event
          tier_list: ['success']                          # tiers in the text grid file to extract
          blocks: [1, 2, 3]                               # blocks to extract
        sample_extractor:
          length: 1.0                                    # Length of each sample in seconds
          rest_period: [0., 3.]                           # extract rest period for future processes
      2:
        interval_extractor:
          data_dir: subject_2/annotations
          start_offset: 0.1
        sample_extractor:
          length: 1.0
          rest_period: [0., 5.]
    settings:
      syllable_identifiers: [i, a]       # Identifiers for syllables in textgrid files.

channel_selection:
  module: channel_selection_main
  params:
    io:
      figure_dir: figures
      output_dir: data/channel_selection
    selections:
      - module: channel_selection.active
        selection_name: active_channels
        params:
          p_threshold: 0.01                    # P-value threshold for significance
          active_time_threshold: 0.1           # Minimum consecutive significant length
          rest_name: ecog_rest
          erp_name: ecog
      - module: channel_selection.discriminative
        selection_name: syllable_discriminative
        params:
          p_threshold: 0.01
          active_time_threshold: 0.1            # Min significant lengths
          onset_time: 0.2                       # Onset time for plotting
          label: syllable
          recording_name: ecog                  # Recording name in npz file
      - module: channel_selection.discriminative
        selection_name: tone_discriminative
        params:
          p_threshold: 0.01
          active_time_threshold: 0.1            # Min significant lengths
          onset_time: 0.2                       # Onset time for plotting
          label: tone
          recording_name: ecog                  # Recording name in npz file

model:
  model: models.simple_classifiers.LogisticRegressionClassifier  # Python path to model class
  model_name: logistic                                           # Short model identifier
  model_kwargs: {}

training:
  module: train_classifier
  params:
    io:
      log_dir: logs                           # Directory for tensorboard logs
    experiment:
      targets: ["syllable", "tone"]
      features: ecog
      separate_models: true
      seed: 42
      repeat: 1
      verbose: 1
      device: cpu
    training:
      train_ratio: 0.7
      vali_ratio: 0.1
      test_ratio: 0.2
      batch_size: 64
      epochs: 10
      lr: 0.0005
      patience: 5
      log_every_n_steps: 10

evaluation:
  metrics: [accuracy, f1_score, confusion_matrix]  # Metrics to compute
  metric_aggregates: [mean, std]                          # Aggregation methods across seeds
